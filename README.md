We propose a cost-sensitive approach to detecting darknet-originating Internet traffic using a Bayesian-optimized feature ranker and a Bayesian-optimized XGBoost classifier. More specifically, we develop a cost-sensitive feature ranker and darknet detector, which are designed to prioritize the detection of darknet traffic by assigning a higher penalty to false negatives than false positives. This is achieved by maximizing the F2 score during hyperparameter optimization. The results show that, with F2 as the objective function, this cost-sensitive approach leads to a detector that is distinctly different from the cost-insensitive detector that maximizes the F1 score (which is also developed in this work). Both cost-sensitive and cost-insensitive detectors surpass the state-of-the-art detector developed on the same dataset in terms of accuracy, with improvements of 1.27% and 2.64%, respectively. The costsensitive detector also outperforms the state-of-the-art by 3.09% in terms of recall and exhibits an area-under-curve ROC of 0.9980. It also reduces false negatives by approximately 61%, while sacrificing less than 1.4% in accuracy relative to its cost-insensitive counterpart. Moreover, we provide insights into the decision-making processes of both cost-sensitive and cost-insensitive models, elucidating and juxtaposing prediction explanations on the same instances to shed light on how cost-sensitivity influences model reasoning at the level of the features. Our findings reveal that the cost-sensitive classifier has a bias toward positive predictions, while the cost-insensitive classifier has a bias toward negative predictions. Finally, both classifiers rely on different features to significantly different extents to arrive at their decisions, meaning that the models are reasoning very differently about inputs despite following similar development processes.

Keywords: Intrusion Detection, Network Intrusion, Security, Machine Learning, Darknet

Hawili, Tariq Ulixes and Ilyas, Muhammad Usman, *A Darknet Traffic Detector Using Bayesian Optimized and Cost-Sensitive Extreme Gradient Boosting*. Available at [SSRN](https://ssrn.com/abstract=4678907) or via [DOI](http://dx.doi.org/10.2139/ssrn.4678907).

The primary code of interest is in the files: `Model1.py`, `Model1.5.py`, `Model2.py`, and `Model3.py`.
